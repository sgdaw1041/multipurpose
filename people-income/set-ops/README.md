**To run db files** 

  Create 3 sampled datafiles, setup schema with tables, and load tables.

1. create 3 sampled datafiles. Within local system, use either python on original dataset,
    
```
    ~./people-income/set-ops$ python3  py_create_samples.py
```

   or use db sql on original table. Note, files must be created by docker container root.

```
    people_income=> \q
    /home/people-income $ exit
    /home/people-income # exit
    sudo docker container exec -it psql14_compose psql people_income -U user-name -f ./home/people-income/set-ops/db_create_samples.sql
```

2. create schema and all tables.
``` 
    /home/people-income $ cd set-ops
    /home/people-income/set-ops $ psql people_income -U user-name -f  create_set_ops.sql
    /home/people-income/set-ops $ psql people_income -U user-name
    people_income=> \dn    
```


3. import data from 3 csv-files--generated by either python or db sql--to respective 3 tables.
```
    people_income=> set search_path to  set_query, data_query;
    people_income=> \d+
    people_income=> \i  db_populate_samples.sql
``` 

4. run set-ops script to load remaining tables and perform analysis.

```
    people_income=> \i db_set_ops.sql    
```

**To run python file** 

1. use same 3 sampled datafiles created in above (db files processing) step 1.

2. from within running python container, browse to local site and click Terminal button to start a new terminal session.
```
  http://127.0.0.1:10000/lab?token=a-token
```

3. from within sub-directory run file to process data using python pandas interactively.
``` 
  ~/work$ cd people-income/set-ops
  ~/work/people-income/set-ops$ python -i py_set_ops.py

```
4. after short run of file, show available session variables and packages.
```
  >>> dir()
```

5. exit the session, close brower, and return to Jupyter terminal.
```
  >>> exit()
  ~/work/people-income/set-ops$
```
6. stop python container.
``` 
  $ sudo docker container my_pyspark stop
```

**Contents** 

- ```create_set_ops.sql``` create schema and tables.
- ```db_create_samples.sql``` create 3 csv-file samples with no duplicate rows per sample from main table.
- ```py_create_samples.py``` create 3 csv-file samples with no replacement from main dataset.
- ```db_populate_samples.sql``` load 3 csv-files sampled from main table; load either python or db generated files.
- ```db_set_ops.sql``` set operation database queries.
- ```py_set_ops.py ``` set operation python pandas code.

